{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## This.ipynb file provides examples for training and testing different models in the Intra-Subject scenario"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-11-14T17:56:52.233698100Z",
     "start_time": "2023-11-14T17:56:46.703757100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.version: 2.10.0 keras.version: 2.10.0\n",
      "is_gpu_available:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "gpu_device_name:  /device:GPU:0\n",
      "name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3660578816\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 8905503206293829448\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\"\n",
      "xla_global_id: 416903419\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "# If you are using the web version of Juypter Notebook, you will need to add the current directory to the path in the sys.path list\n",
    "# import sys\n",
    "# path = os.path.join(os.getcwd())\n",
    "# sys.path.append(path) \n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from train.trainTest import ModelTrainTest\n",
    "from tensorflow.python.client import device_lib\n",
    "from IPython.display import clear_output as clear\n",
    "%matplotlib inline\n",
    "# print(plt.style.available)\n",
    "plt.style.use('Solarize_Light2')\n",
    "print('tf.version:',tf.__version__,'keras.version:',keras.__version__)\n",
    "print('is_gpu_available: ', tf.config.list_physical_devices('GPU'))\n",
    "print('gpu_device_name: ', tf.test.gpu_device_name())\n",
    "local_device_protos = device_lib.list_local_devices()\n",
    "[print(x) for x in local_device_protos if x.device_type == 'GPU'] \n",
    "# Specify Gpu-0 for model training\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "# Allocate minimum memory based on actual usage\n",
    "# gpus = tf.config.list_physical_devices('GPU')\n",
    "# for gpu in gpus:\n",
    "#     tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\"\"\"parameters settings\"\"\"\n",
    "attention = 'SA' # One of ['None', 'SE', 'SA'].\n",
    "withTransfer = False\n",
    "trainPlot = False\n",
    "ReduceLR = True\n",
    "EarlyStop = True\n",
    "saveModelHistory = True\n",
    "savePredictResult = True\n",
    "savePlotResult = True"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T17:56:52.238157600Z",
     "start_time": "2023-11-14T17:56:52.233698100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "subType = 'targetSubjects'\n",
    "task = 'N-N' # When withTransfer=False, the task parameter has no effect\n",
    "targetSubjects = [['1N', '2N', '3N', '4N', '5N', '6N', '7N', '8N', '9N', '10N', '11N'],\n",
    "                  ['1A', '2A', '3A', '4A', '5A', '6A', '7A', '8A', '9A', '10A', '11A']]\n",
    "modelTypes = ['CNN-LSTM', 'CNN-BiLSTM', 'CNN-GRU', 'CNN-BiGRU', 'CNN-TCN', 'Sinc-LSTM', 'Sinc-BiLSTM', 'Sinc-GRU', 'Sinc-BiGRU', 'Sinc-TCN']\n",
    "\n",
    "for modelType in modelTypes:\n",
    "    for j in range(len(targetSubjects)):\n",
    "        for i in range(len(targetSubjects[0])):\n",
    "            clear()\n",
    "            targetSubject=targetSubjects[j][i]\n",
    "            print('Intra-Subject model training and testing of: model-%s, subject-%s' % (modelType, targetSubject))\n",
    "            train_utils = ModelTrainTest(model_type=modelType, attention=attention)\n",
    "            train_utils.train(with_transfer=withTransfer, task=task, target_subject=targetSubject, sub_type=subType, \n",
    "                              train_plot=trainPlot, reduce_lr=ReduceLR, early_stop=EarlyStop, save_model_history=saveModelHistory, \n",
    "                              save_predict_result=savePredictResult, save_plot_result=savePlotResult)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu-2.6",
   "language": "python",
   "name": "tf-gpu-2.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
